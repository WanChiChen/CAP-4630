{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4Problem3A.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wc6255/CAP-4630/blob/master/HW4/HW4Problem3A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSrgMJ5vKFzQ",
        "colab_type": "text"
      },
      "source": [
        "# Adaption of \"Fine-tuning VGG16\" on ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIW7bZaAK-Hf",
        "colab_type": "text"
      },
      "source": [
        "This implementation uses 2 hidden layers:\n",
        "\n",
        "2 consectuve layers of size 256 using the ReLu function\n",
        "\n",
        "1 output layer using sigmoid function\n",
        "\n",
        "This is based on section 5.3 *Using a pretrained convnet* of the book *Deep learning with Python* by Francois Chollet. I have made several changes to the code. I use the data that is already provided by Google. I don't download the data from Kaggle as in the deep learning book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsBq__dVo2pj",
        "colab_type": "text"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g6ETAM9o54M",
        "colab_type": "text"
      },
      "source": [
        "Feature extraction consists of using the representations learned by a previous network to extract interesting features from new samples. These features are then run through a new classifier, which is trained from scratch.\n",
        "\n",
        "We will use here the convolutional base of the VGG16 model to extract the features. We will feed these features to a densely connected classifier with dropout. We will fine-tune some layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqIG8QHMLNOn",
        "colab_type": "text"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3I1jd7cKV6_",
        "colab_type": "text"
      },
      "source": [
        "Download the example data, a zip. of 2,000 JPG pictures of cats and dogs and extract it locally in ```/tmp```.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWjprHEXJ5Qi",
        "colab_type": "code",
        "outputId": "6f3d5bf1-75ea-4e1d-e8a7-ee8e81c98645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-20 01:38:09--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.143.128, 2a00:1450:4013:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.143.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_   6%[>                   ]   4.01M  15.9MB/s               \r        /tmp/cats_a  82%[===============>    ]  54.28M   120MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   138MB/s    in 0.5s    \n",
            "\n",
            "2020-04-20 01:38:10 (138 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvoHtdA-K6Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shZiOBnJMyy_",
        "colab_type": "text"
      },
      "source": [
        "Note that the data provided by Google does not have a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL8ikM89LlsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inyP8bcdXnn-",
        "colab_type": "text"
      },
      "source": [
        "## Build network with ResNet50 convolution base and custom densely connected layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ48W5T9rHWu",
        "colab_type": "text"
      },
      "source": [
        "### Load the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0FgtANCXm_H",
        "colab_type": "code",
        "outputId": "d02c218a-1387-416f-a866-1060f0408c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications import ResNet50\n",
        "\n",
        "conv_base = ResNet50(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))\n",
        "conv_base.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 3s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 75, 75, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 75, 75, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 38, 38, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 38, 38, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 38, 38, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 38, 38, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 38, 38, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 38, 38, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 38, 38, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 38, 38, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 38, 38, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 19, 19, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 19, 19, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 19, 19, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 10, 10, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 10, 10, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 10, 10, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 10, 10, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 10, 10, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 10, 10, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 10, 10, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 10, 10, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 10, 10, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 10, 10, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 5, 5, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 5, 5, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 5, 5, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 5, 5, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 5, 5, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 5, 5, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 5, 5, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 5, 5, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 5, 5, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6OBHOO9q1ou",
        "colab_type": "text"
      },
      "source": [
        "### Freeze the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UleRo4Dpq6Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfx6PqhPrb7Q",
        "colab_type": "text"
      },
      "source": [
        "### Concatenate the convolutional base and densely connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUpmocDAO3xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "#model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh6gZSeAjF7c",
        "colab_type": "code",
        "outputId": "5ac2883d-1659-4546-8c50-2e055e4728e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 5, 5, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 36,761,217\n",
            "Trainable params: 13,173,505\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZjBiddhi5Qj",
        "colab_type": "text"
      },
      "source": [
        "## Train the model end to end with frozen convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfAQlC2Oi41L",
        "colab_type": "code",
        "outputId": "f0ca062c-5771-4f23-a1c0-d00d437e2b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "# data augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "# compile model\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer=optimizers.RMSprop(lr=2e-5), \n",
        "    metrics=['acc'])\n",
        "\n",
        "# train\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.3843 - acc: 0.8300 - val_loss: 0.7736 - val_acc: 0.5000\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.2657 - acc: 0.8825 - val_loss: 0.8336 - val_acc: 0.5000\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2159 - acc: 0.9030 - val_loss: 0.7094 - val_acc: 0.4970\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2115 - acc: 0.9145 - val_loss: 0.6633 - val_acc: 0.4970\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2248 - acc: 0.9140 - val_loss: 0.6937 - val_acc: 0.4970\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2003 - acc: 0.9230 - val_loss: 0.7693 - val_acc: 0.5000\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2005 - acc: 0.9235 - val_loss: 0.6707 - val_acc: 0.4980\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2147 - acc: 0.9145 - val_loss: 0.7450 - val_acc: 0.4980\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1724 - acc: 0.9250 - val_loss: 0.7616 - val_acc: 0.5000\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1670 - acc: 0.9320 - val_loss: 0.7682 - val_acc: 0.4980\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1681 - acc: 0.9345 - val_loss: 0.7209 - val_acc: 0.5000\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1726 - acc: 0.9320 - val_loss: 0.6926 - val_acc: 0.5030\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1706 - acc: 0.9365 - val_loss: 0.6633 - val_acc: 0.5000\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.1587 - acc: 0.9360 - val_loss: 0.7266 - val_acc: 0.5000\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1581 - acc: 0.9415 - val_loss: 0.6926 - val_acc: 0.5100\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1607 - acc: 0.9410 - val_loss: 0.6916 - val_acc: 0.5210\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1585 - acc: 0.9400 - val_loss: 0.6636 - val_acc: 0.5000\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1429 - acc: 0.9445 - val_loss: 0.8318 - val_acc: 0.5000\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1254 - acc: 0.9500 - val_loss: 0.7041 - val_acc: 0.5000\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1280 - acc: 0.9535 - val_loss: 0.6889 - val_acc: 0.5000\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1374 - acc: 0.9470 - val_loss: 0.7761 - val_acc: 0.5000\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1491 - acc: 0.9400 - val_loss: 0.6563 - val_acc: 0.5000\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1394 - acc: 0.9465 - val_loss: 0.7226 - val_acc: 0.5000\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1369 - acc: 0.9480 - val_loss: 0.6872 - val_acc: 0.5000\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1255 - acc: 0.9560 - val_loss: 0.8354 - val_acc: 0.5000\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1098 - acc: 0.9565 - val_loss: 0.7725 - val_acc: 0.5000\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1099 - acc: 0.9555 - val_loss: 0.8523 - val_acc: 0.5000\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1262 - acc: 0.9540 - val_loss: 0.8072 - val_acc: 0.5000\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1123 - acc: 0.9540 - val_loss: 0.6993 - val_acc: 0.5000\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1118 - acc: 0.9570 - val_loss: 1.0563 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqRc_vHKc92U",
        "colab_type": "text"
      },
      "source": [
        "## Display curves of loss and accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybWwdzz9bwuQ",
        "colab_type": "code",
        "outputId": "797c5ab4-43f3-4cdc-caed-4614a233f659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOWsxpey8lN0",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkVMx8N8qMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyN-J7rs9cvo",
        "colab_type": "code",
        "outputId": "fb5e0feb-5b97-467a-febb-0079d5f27cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile model\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    #\n",
        "    # choose a smaller learning rate\n",
        "    #\n",
        "    optimizer=optimizers.RMSprop(lr=1e-5), \n",
        "    metrics=['acc'])\n",
        "\n",
        "# train\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.1017 - acc: 0.9585 - val_loss: 1.7606 - val_acc: 0.4970\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.1064 - acc: 0.9625 - val_loss: 2.2710 - val_acc: 0.4170\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.1112 - acc: 0.9575 - val_loss: 4.7343 - val_acc: 0.4450\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0871 - acc: 0.9630 - val_loss: 2.4027 - val_acc: 0.4640\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.0966 - acc: 0.9645 - val_loss: 1.7811 - val_acc: 0.5030\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0830 - acc: 0.9680 - val_loss: 1.3371 - val_acc: 0.5700\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0855 - acc: 0.9670 - val_loss: 1.1059 - val_acc: 0.7320\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.0942 - acc: 0.9700 - val_loss: 1.0529 - val_acc: 0.8610\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.0914 - acc: 0.9705 - val_loss: 0.0593 - val_acc: 0.9200\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0879 - acc: 0.9665 - val_loss: 0.1343 - val_acc: 0.9470\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0883 - acc: 0.9640 - val_loss: 0.0118 - val_acc: 0.9530\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.0842 - acc: 0.9645 - val_loss: 0.1464 - val_acc: 0.9510\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0652 - acc: 0.9755 - val_loss: 0.1751 - val_acc: 0.9530\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0861 - acc: 0.9685 - val_loss: 0.0705 - val_acc: 0.9560\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.0926 - acc: 0.9705 - val_loss: 0.0065 - val_acc: 0.9590\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0721 - acc: 0.9700 - val_loss: 0.2734 - val_acc: 0.9480\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0799 - acc: 0.9735 - val_loss: 0.0582 - val_acc: 0.9620\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.0851 - acc: 0.9695 - val_loss: 0.2410 - val_acc: 0.9540\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0531 - acc: 0.9810 - val_loss: 0.3046 - val_acc: 0.9550\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0882 - acc: 0.9705 - val_loss: 0.1555 - val_acc: 0.9590\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0767 - acc: 0.9705 - val_loss: 0.1740 - val_acc: 0.9480\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0726 - acc: 0.9720 - val_loss: 0.6408 - val_acc: 0.9430\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0828 - acc: 0.9690 - val_loss: 0.1612 - val_acc: 0.9580\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0580 - acc: 0.9785 - val_loss: 0.0554 - val_acc: 0.9620\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0800 - acc: 0.9750 - val_loss: 0.0355 - val_acc: 0.9550\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.0775 - acc: 0.9675 - val_loss: 0.0291 - val_acc: 0.9470\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.0678 - acc: 0.9750 - val_loss: 0.1304 - val_acc: 0.9610\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.0661 - acc: 0.9750 - val_loss: 0.4531 - val_acc: 0.9500\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0713 - acc: 0.9730 - val_loss: 0.4825 - val_acc: 0.9540\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0840 - acc: 0.9730 - val_loss: 0.1652 - val_acc: 0.9470\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0649 - acc: 0.9760 - val_loss: 0.0995 - val_acc: 0.9600\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.0675 - acc: 0.9770 - val_loss: 0.1191 - val_acc: 0.9480\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.0662 - acc: 0.9785 - val_loss: 0.4190 - val_acc: 0.9440\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0620 - acc: 0.9810 - val_loss: 0.0460 - val_acc: 0.9580\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0590 - acc: 0.9770 - val_loss: 0.1194 - val_acc: 0.9480\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.0845 - acc: 0.9675 - val_loss: 0.1338 - val_acc: 0.9520\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0616 - acc: 0.9765 - val_loss: 0.0235 - val_acc: 0.9540\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0623 - acc: 0.9780 - val_loss: 0.2512 - val_acc: 0.9480\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0488 - acc: 0.9855 - val_loss: 0.2565 - val_acc: 0.9480\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.0654 - acc: 0.9785 - val_loss: 0.0105 - val_acc: 0.9540\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0516 - acc: 0.9810 - val_loss: 0.0012 - val_acc: 0.9440\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0756 - acc: 0.9705 - val_loss: 0.2184 - val_acc: 0.9400\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0707 - acc: 0.9735 - val_loss: 0.0133 - val_acc: 0.9470\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0629 - acc: 0.9750 - val_loss: 0.0147 - val_acc: 0.9480\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0659 - acc: 0.9765 - val_loss: 0.3668 - val_acc: 0.9600\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0570 - acc: 0.9800 - val_loss: 2.7977e-04 - val_acc: 0.9490\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0721 - acc: 0.9705 - val_loss: 0.1392 - val_acc: 0.9540\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0560 - acc: 0.9800 - val_loss: 0.2737 - val_acc: 0.9530\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0460 - acc: 0.9805 - val_loss: 0.0149 - val_acc: 0.9500\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0753 - acc: 0.9775 - val_loss: 0.3679 - val_acc: 0.9430\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0567 - acc: 0.9805 - val_loss: 0.2159 - val_acc: 0.9400\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0492 - acc: 0.9795 - val_loss: 0.0401 - val_acc: 0.9550\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0652 - acc: 0.9785 - val_loss: 0.0260 - val_acc: 0.9580\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0439 - acc: 0.9820 - val_loss: 0.0955 - val_acc: 0.9540\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0546 - acc: 0.9810 - val_loss: 0.2283 - val_acc: 0.9450\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0649 - acc: 0.9785 - val_loss: 0.0028 - val_acc: 0.9480\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0555 - acc: 0.9795 - val_loss: 0.0663 - val_acc: 0.9540\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0546 - acc: 0.9770 - val_loss: 0.1533 - val_acc: 0.9560\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0535 - acc: 0.9820 - val_loss: 0.4652 - val_acc: 0.9550\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0443 - acc: 0.9835 - val_loss: 0.0059 - val_acc: 0.9540\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0633 - acc: 0.9765 - val_loss: 0.4729 - val_acc: 0.9540\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0556 - acc: 0.9790 - val_loss: 0.0591 - val_acc: 0.9570\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0530 - acc: 0.9845 - val_loss: 0.0927 - val_acc: 0.9550\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0489 - acc: 0.9805 - val_loss: 0.1771 - val_acc: 0.9570\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.0508 - acc: 0.9810 - val_loss: 0.2622 - val_acc: 0.9450\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0493 - acc: 0.9830 - val_loss: 0.0305 - val_acc: 0.9580\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0542 - acc: 0.9815 - val_loss: 0.1384 - val_acc: 0.9510\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0547 - acc: 0.9790 - val_loss: 0.1805 - val_acc: 0.9550\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0471 - acc: 0.9840 - val_loss: 0.0539 - val_acc: 0.9570\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.0435 - acc: 0.9845 - val_loss: 0.0044 - val_acc: 0.9570\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.0535 - acc: 0.9795 - val_loss: 0.1983 - val_acc: 0.9550\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0485 - acc: 0.9820 - val_loss: 0.0149 - val_acc: 0.9590\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.0488 - acc: 0.9845 - val_loss: 0.0670 - val_acc: 0.9500\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0472 - acc: 0.9800 - val_loss: 0.3733 - val_acc: 0.9570\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0486 - acc: 0.9835 - val_loss: 0.0254 - val_acc: 0.9530\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0418 - acc: 0.9825 - val_loss: 0.3914 - val_acc: 0.9530\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.0527 - acc: 0.9840 - val_loss: 0.0519 - val_acc: 0.9520\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0321 - acc: 0.9895 - val_loss: 0.6404 - val_acc: 0.9590\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0631 - acc: 0.9790 - val_loss: 0.6997 - val_acc: 0.9460\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.0400 - acc: 0.9860 - val_loss: 0.3402 - val_acc: 0.9590\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0476 - acc: 0.9845 - val_loss: 0.2207 - val_acc: 0.9580\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0481 - acc: 0.9805 - val_loss: 0.3103 - val_acc: 0.9480\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0366 - acc: 0.9860 - val_loss: 0.0241 - val_acc: 0.9550\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0341 - acc: 0.9900 - val_loss: 6.3525e-04 - val_acc: 0.9520\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0355 - acc: 0.9885 - val_loss: 0.0054 - val_acc: 0.9550\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0291 - acc: 0.9880 - val_loss: 0.0101 - val_acc: 0.9550\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.0352 - acc: 0.9900 - val_loss: 0.0097 - val_acc: 0.9540\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0630 - acc: 0.9765 - val_loss: 0.4460 - val_acc: 0.9510\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0505 - acc: 0.9830 - val_loss: 0.2136 - val_acc: 0.9530\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0362 - acc: 0.9880 - val_loss: 0.0116 - val_acc: 0.9490\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0431 - acc: 0.9845 - val_loss: 0.0138 - val_acc: 0.9620\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.0447 - acc: 0.9810 - val_loss: 0.2853 - val_acc: 0.9480\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0394 - acc: 0.9870 - val_loss: 0.0127 - val_acc: 0.9510\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.0332 - acc: 0.9885 - val_loss: 9.5619e-05 - val_acc: 0.9530\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0449 - acc: 0.9855 - val_loss: 0.1833 - val_acc: 0.9570\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.0392 - acc: 0.9850 - val_loss: 0.1487 - val_acc: 0.9590\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.0337 - acc: 0.9875 - val_loss: 0.3121 - val_acc: 0.9560\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0414 - acc: 0.9855 - val_loss: 0.0102 - val_acc: 0.9550\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.0484 - acc: 0.9840 - val_loss: 0.0161 - val_acc: 0.9510\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0428 - acc: 0.9850 - val_loss: 0.6730 - val_acc: 0.9530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVBQgh5M-Rtz",
        "colab_type": "text"
      },
      "source": [
        "## Display learning curves during fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbkIw7Ie-NP4",
        "colab_type": "code",
        "outputId": "c14f7556-4b28-4ded-d665-08a89058dd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obQi6N4ZShdi",
        "colab_type": "text"
      },
      "source": [
        "This looks like overfitting. I should try  adding dropout for the densely connected layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he3Nw6TOJwjx",
        "colab_type": "text"
      },
      "source": [
        "## Print out validation loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVQtrk7uJdhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss, val_acc = model.evaluate_generator(validation_generator, steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpdddLi1SUMe",
        "colab_type": "code",
        "outputId": "01604d66-e33a-4699-bf7a-37ab82d42eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Validation loss:\", val_loss)\n",
        "print(\"Validation accuracy:\", val_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.298856258392334\n",
            "Validation accuracy: 0.953000009059906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ww756WToby8",
        "colab_type": "text"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lTUpUdwobKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fname = 'cats_and_dogs_small_4copy.h5' \n",
        "model.save(model_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhEoI8ZTok-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "707dd122-a690-49b9-adae-d0ae2a6c1094"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNEL4CCcS0Oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "path = F\"/content/gdrive/My Drive/{model_fname}\" \n",
        "torch.save(model.save(model_fname), path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}